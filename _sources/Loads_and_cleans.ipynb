{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9141f92",
   "metadata": {},
   "source": [
    "# Load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee9b386e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ezodf\n",
    "import re\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import src.data_loading.loads_from_url as lfu\n",
    "import src.utils.loads_from_url as utils\n",
    "import src.data_cleaning.modify_dfs as mdf\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = re.split(r\"[A-Za-z]+$\",cwd)[0]\n",
    "\n",
    "folder_path = os.path.join(cwd, 'data')\n",
    "\n",
    "file_path = []\n",
    "for file_ in os.listdir(folder_path):\n",
    "    if file_.endswith('.ods') and not re.search(r'^_',file_):\n",
    "        file_path.append(os.path.join(folder_path, file_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402c39a",
   "metadata": {},
   "source": [
    "## Load a file\n",
    "\n",
    "The file format changes with each file. So had to do a slightly convoluted load.\n",
    "\n",
    "Also we want to ignore sheets with names: Introduction, Summary or including SUM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f11d90",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def import_ods(fname):\n",
    "    \"\"\"\n",
    "    imports ods files given a filename and returns a pd dataframe\n",
    "    used with function import_ods_inner which does the importing for each sheet != 0\n",
    "    \n",
    "    Args:\n",
    "        fname (string): a string to location of the ods file\n",
    "    \n",
    "    Returns:\n",
    "        a dataframe of the ods file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    doc = ezodf.opendoc(fname)\n",
    "    \n",
    "    for i, sheet in enumerate(doc.sheets):\n",
    "        product = sheet.name\n",
    "\n",
    "        if product != 'Introduction' and product != 'Summary' and not re.search(r\"SUM\",product): #ignore 1st sheet\n",
    "            \n",
    "            # main call\n",
    "            df_new, bool_sheet = _import_ods_inner(sheet)\n",
    "            \n",
    "            # if sheet is not a bad sheet\n",
    "            if bool_sheet == True:\n",
    "                df_new['product'] = product\n",
    "                df_new.columns = df_new.columns.str.strip()\n",
    "                try:\n",
    "                    if len(df_new.columns)>3:\n",
    "                        df = pd.concat([df,df_new])\n",
    "                    else:\n",
    "                        print(f\"{product} not enough columns\")\n",
    "                except:\n",
    "                    df = df_new\n",
    "\n",
    "                df.reset_index(inplace=True,drop=True)    \n",
    "                \n",
    "        else:\n",
    "            fname_ = fname.split('\\\\')[-1].split('.')[0]\n",
    "            print(f'Failed to load {fname_}: {product}')\n",
    "            \n",
    "\n",
    "    return df\n",
    "\n",
    "def _import_ods_inner(sheet):\n",
    "    \"\"\"\n",
    "    inner function of import_ods\n",
    "    takes individual sheets and returns a pd df \n",
    "    \"\"\"\n",
    "    \n",
    "    data_sheet = []\n",
    "    got_colname =False\n",
    "    for i,row in enumerate(sheet.rows()):\n",
    "\n",
    "        if got_colname == False:\n",
    "            column_names = [cell.value for cell in row]\n",
    "\n",
    "            if column_names[0] == 'Sample ID':\n",
    "                got_colname = True\n",
    "                     \n",
    "        else:\n",
    "            data_sheet.append( [cell.value for cell in row] )\n",
    "            \n",
    "    \n",
    "    if got_colname:\n",
    "        ddf = pd.DataFrame(data_sheet)\n",
    "\n",
    "        ddf.columns = column_names\n",
    "\n",
    "        # delete none column\n",
    "        try:\n",
    "            del ddf[None]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # fill based on previous values    \n",
    "        ddf.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        return ddf,True\n",
    "    else:\n",
    "        return [],False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b37a6",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "df = import_ods(file_path[0])\n",
    "print(f\"\\nLength of df is {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82310b9e",
   "metadata": {},
   "source": [
    "## Load multiple files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c54567f",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "def import_all_ods(folder_path):\n",
    "    \"\"\"\n",
    "    Imports all ods files in a folder and returns a pd df\n",
    "    \n",
    "    Args:\n",
    "        folder_path (string): a string to location of the ods file\n",
    "    \n",
    "    Returns:\n",
    "        pd.Dataframe (mod_df): a dataframe of all ods files combined,\n",
    "            with modifcations applied\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_column_names = {'Sampling Point':'Retail Outlet',\n",
    "                     'Packer / Manufacturer':'Packer / Manufacturer / Importer'}\n",
    "    \n",
    "    \n",
    "    file_path = []\n",
    "    for file_ in os.listdir(folder_path):\n",
    "        if file_.endswith('.ods') and not re.search(r'^_',file_):\n",
    "            file_path.append(os.path.join(folder_path, file_) )\n",
    "    \n",
    "    all_df_lst = []\n",
    "    for file_ in file_path:\n",
    "        fname_ = file_.split('\\\\')[-1].split('.')[0]\n",
    "        print(f\"Importing {fname_}\")\n",
    "        df = import_ods(file_)\n",
    "        df = df.rename(columns=dict_column_names)\n",
    "        \n",
    "        # put each modified df into a list\n",
    "        all_df_lst.append(df)\n",
    "\n",
    "    # concat all the modified dfs   \n",
    "    df_all = pd.concat(all_df_lst)\n",
    "\n",
    "    # modify the concatenated dfs\n",
    "#     mod_df = md.modify_df(df_all)\n",
    "\n",
    "    return df_all\n",
    "\n",
    "all_dfs = import_all_ods(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "406baec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 2016_annual_data\n",
      "Importing 2017_annual_data\n",
      "Importing 2018_annual_data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlfu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_all_ods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Pesticide\\src\\data_loading\\loads_from_url.py:41\u001b[0m, in \u001b[0;36mimport_all_ods\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     39\u001b[0m fname_ \u001b[38;5;241m=\u001b[39m file_\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImporting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mimport_ods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mdict_column_names)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# put each modified df into a list\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Pesticide\\src\\data_loading\\loads_from_url.py:78\u001b[0m, in \u001b[0;36mimport_ods\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     73\u001b[0m product \u001b[38;5;241m=\u001b[39m sheet\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m product \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntroduction\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m product \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSummary\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUM\u001b[39m\u001b[38;5;124m\"\u001b[39m,product): \u001b[38;5;66;03m#ignore 1st sheet\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     \n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# main call\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     df_new, bool_sheet \u001b[38;5;241m=\u001b[39m \u001b[43m_import_ods_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# if sheet is not a bad sheet\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bool_sheet \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Pesticide\\src\\data_loading\\loads_from_url.py:120\u001b[0m, in \u001b[0;36m_import_ods_inner\u001b[1;34m(sheet)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows()):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m got_colname \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         column_names \u001b[38;5;241m=\u001b[39m [cell\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m column_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample ID\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    123\u001b[0m             got_colname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Pesticide\\src\\data_loading\\loads_from_url.py:120\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows()):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m got_colname \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         column_names \u001b[38;5;241m=\u001b[39m [\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m column_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample ID\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    123\u001b[0m             got_colname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\44781\\anaconda3\\envs\\ons-env\\lib\\site-packages\\ezodf\\cells.py:72\u001b[0m, in \u001b[0;36mCell.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m---> 72\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_type\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m  t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\44781\\anaconda3\\envs\\ons-env\\lib\\site-packages\\ezodf\\cells.py:59\u001b[0m, in \u001b[0;36mCell.value_type\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_attr(\u001b[43mCN\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffice:value-type\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lfu.import_all_ods(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1fca5",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e6f4e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 2016_annual_data\n",
      "Importing 2017_annual_data\n",
      "Importing 2018_annual_data\n",
      "Importing Apr_2022_rolling_report_v2\n",
      "Importing August_2022_rolling_reports\n",
      "Importing July_2022_rolling_reports\n",
      "Importing June_2022_rolling_reports\n",
      "Importing May_2022_rolling_report\n",
      "Importing October_2022_rolling_reports\n",
      "Importing Q1_2018_quarterly_data\n",
      "Importing Q1_2019_quarterly_data\n",
      "Importing Q1_2020_quarterly_data\n",
      "Importing Q1_2021_quarterly_data\n",
      "Importing Q2_2018_quarterly_data\n",
      "Importing Q2_2019_quarterly_data\n",
      "Importing Q2_2021_quarterly_data\n",
      "Importing Q2_Q3_2020_Data\n",
      "Importing Q3_2018_quarterly_data\n",
      "Importing Q3_2019_quarterly_data\n",
      "Importing Q3_2021_quarterly_data\n",
      "Importing Q4_2018_quarterly_data\n",
      "Importing Q4_2019_quarterly_data\n",
      "Importing Q4_2020_Data\n",
      "Importing Q4_2021_PRIF_Quarterly_Report\n",
      "Importing September_2022_rolling_reports\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import re\n",
    "import src.data_loading.loads_from_url as lfu\n",
    "cwd = os.getcwd()\n",
    "cwd = re.split(r'[A-Za-z]+$',cwd)[0]\n",
    "cwd = os.path.join(cwd,'data')\n",
    "file = os.path.join(cwd,'combined_df.csv')\n",
    "lfu.save_dfs(folder_path = cwd, file_folder=file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
